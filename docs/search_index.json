[
<<<<<<< HEAD
["index.html", "Dashboards project Chapter 1 Introduction 1.1 Executive summary 1.2 What is an automated analysis? 1.3 Why not have one project for each automated analysis? 1.4 Important repositories", " Dashboards project Richard White 2018-11-13 Chapter 1 Introduction 1.1 Executive summary The dashboards project is a project at FHI concerned with running automated analyses on data. In principle, the dashboards project is split up into three parts: The umbrella infrastructure (i.e. Docker containers, continuous integration, chron jobs, etc.) The R package for each automated analysis Integrating the R package into the physical system (e.g. specifying where the data is) 1.2 What is an automated analysis? An automated analysis is any analysis that: Will be repeated multiple times in the future Always has an input dataset with consistent file structure Always has the same expected output (e.g. tables, graphs, reports) 1.3 Why not have one project for each automated analysis? Automated analyses have a lot of code and infrastructure in common. Automated analyses: Need their code to be tested via unit testing to ensure the results are correct Need their code to be tested via integration testing to ensure everything runs Need to be run at certain times Need to be able to send emails notifying people that the analyses have finished running Need to make their results accessible to the relevant people By combining them all in one umbrella project we can force everyone to use the same infrastructure and coding principles, so we: Only need to solve a problem once Only need to maintain one system Can easily work on multiple projects, as we all speak the same language 1.4 Important repositories 1.4.1 Infrastructure https://github.com/raubreywhite/dashboards_control/ (private) This contains the Docker files, cronfiles, all bash scripts, etc. https://folkehelseinstituttet.github.io/dashboards/ (this one) This contains the R executable for each automated analysis. https://folkehelseinstituttet.github.io/fhi/ This is an R package that contains helper functions. 1.4.2 Automated analyses R packages https://folkehelseinstituttet.github.io/dashboards_sykdomspuls/ https://folkehelseinstituttet.github.io/dashboards_normomo/ https://folkehelseinstituttet.github.io/dashboards_sykdomspuls_pdf/ https://folkehelseinstituttet.github.io/dashboards_sykdomspuls_log/ "],
["integrating-the-r-package-into-the-physical-system.html", "Chapter 2 Integrating the R package into the physical system 2.1 Summary 2.2 RunProcess.R 2.3 0_run.sh 2.4 RunTest.R", " Chapter 2 Integrating the R package into the physical system 2.1 Summary An R package is not enough to run an analysis – something needs to physically call the functions inside the R package. That is, the R package needs to be integrated into the physical system. Everything related to integrating the R package into the physical system lives in the dashboards repository. Inside the dashboards repository we have: - dev/ |-- src/ |-- sykdomspuls/ |-- 0_run.sh |-- RunProcess.R |-- RunTest.R |-- normomo/ |-- 0_run.sh |-- RunProcess.R |-- RunTest.R |-- sykdomspuls_log/ |-- 0_run.sh |-- RunProcess.R |-- RunTest.R |-- sykdomspuls_pdf/ |-- 0_run.sh |-- RunProcess.R |-- RunTest.R 2.2 RunProcess.R 2.2.1 Aim An automated analysis needs to: Know the location of the data/results folders. Check for new data in these folders. If no new data - then quit. Load in the data. Load in the analysis functions. Run the analyses. Save the results. RunProcess.R is responsible for these tasks. We can think of it as an extremely short and extremely high-level script that implements the analysis scripts. Depending on the automated analysis RunProcess.R can be run every two minutes (constantly checking for new data), or once a week (when we know that data will only be available on a certain day/time). 2.2.2 Bounded context Only one instance of RunProcess.R can be run at a time. Data only exists on physical folders on the system. The following folder structure exists on the system (here the name of the automated analysis is ANALYSIS): /data_raw/ |-- ANALYSIS/ /data_clean/ |-- ANALYSIS/ /data_app/ |-- ANALYSIS/ /results/ |-- ANALYSIS/ /src/ |-- ANALYSIS/ |-- 0_run.sh |-- RunProcess.R |-- RunTest.R Point #1 is important because if RunProcess.R is run every 2 minutes (constantly checking for new data) but the analyses take 3 hours to run, then we need to ensure that only one instance of RunProcess.R can be run at a time. Point #2 is important because sometimes: Data files need to be downloaded from external SFTP servers (normomo, sykdomspulslog). Results files need to be uploaded to external SFTP servers (sykdomspuls). If we include code to download/upload the files from SFTP servers inside RunProcess.R then it makes it very difficult to test RunProcess.R (because we will then need to simulate SFTP servers inside our testing infrastructure). If we know that RunProcess.R only accesses files that are available on physical folders in the system, then our testing infrastructure is a lot easier to create and maintain. 2.3 0_run.sh 2.3.1 Aim The aim of 0_run.sh is to ensure that: Points 1 and 2 of the bounded context of RunProcess.R happen Run RunProcess.R With regards to the bounded context, we ensure that only one instance of RunProcess.R is run at a time through the use of flock. (If neccessary) with regards to the bounded context, we use sshpass, sftp, and ncftpput to download/upload files from SFTP servers. We then run RunProcess.R with a standard call: /usr/local/bin/Rscript /src/ANALYSIS/RunProcess.R 2.4 RunTest.R 2.4.1 Aim The aim of RunTest.R is to perform integration testing on the automated analysis. This integration testing is performed as part of the Jenkins build pipeline. "],
["r-packages.html", "Chapter 3 R packages 3.1 Summary 3.2 Requirements 3.3 Deployment via travis-ci and drat", " Chapter 3 R packages 3.1 Summary Each automated analysis has its own R package: sykdomspuls normomo sykdomspulspdf sykdomspulslog Each R package contains all of the code necessary for that automated analysis. Typical examples are: Data cleaning Signal analysis Graph generation Report generation 3.2 Requirements The R packages should be developed using unit testing as implemented in the testthat package. Furthermore, the R package should operate (and be able to be tested) independently from the real datasets on the system. This is because the real datasets cannot be shared publically or uploaded to github. To circumvent this issue, each package will need to develop functions that can generate fake data. GenFakeDataRaw is one example from sykdomspuls. We also require that unit tests are created to test the formatting/structure of results. ValidateAnalysisResults is one example from sykdomspuls, where the names of the data.table are checked against reference values to ensure that the structure of the results are not accidentally changed. 3.3 Deployment via travis-ci and drat Unit testing is then automatically run using travis-ci. If the R package passes all tests, then we use drat to deploy a built version of the package to Folkehelseinstituttet’s R repository: https://folkehelseinstituttet.github.io/drat/. "],
["umbrella-infrastructure.html", "Chapter 4 Umbrella Infrastructure 4.1 Executive summary 4.2 What is an automated analysis? 4.3 Why not have one project for each automated analysis?", " Chapter 4 Umbrella Infrastructure Three computers 4.1 Executive summary The dashboards project is a project at FHI concerned with running automated analyses on data. In principle, the dashboards project is split up into three parts: The overarching infrastructure (i.e. Docker containers, continuous integration, chron jobs, etc.) The R package for each automated analysis The executable for each automated analysis 4.2 What is an automated analysis? An automated analysis is any analysis that: Will be repeated multiple times in the future Always has an input dataset with consistent file structure Always has the same expected output (e.g. tables, graphs, reports) 4.3 Why not have one project for each automated analysis? Automated analyses have a lot of code and infrastructure in common. Automated analyses: Need their code to be tested via unit testing to ensure the results are correct Need their code to be tested via integration testing to ensure everything runs Need to be run at certain times Need to be able to send emails notifying people that the analyses have finished running Need to make their results accessible to the relevant people By combining them all in one umbrella project we can force everyone to use the same infrastructure, so we: Only need to solve a problem once Only need to maintain one system Can easily work on multiple projects, as we all speak the same language "],
["contributing.html", "Chapter 5 Contributing 5.1 Development guidelines 5.2 Code style", " Chapter 5 Contributing 5.1 Development guidelines We try to follow the GitHub flow for development. Fork [this repo][repo] and clone it to your computer. To learn more about this process, see this guide. Add the Folkehelseinstituttet repository as your upstream: git remote add upstream https://github.com/folkehelseinstituttet/ORIGINAL_REPOSITORY.git If you have forked and cloned the project before and it has been a while since you worked on it, merge changes from the original repo to your clone by using: git fetch upstream git merge upstream/master Open the RStudio project file (.Rproj). Make your changes: Write your code. Test your code (bonus points for adding unit tests). Document your code (see function documentation above). Do an R CMD check using devtools::check() and aim for 0 errors and warnings. Commit your changes locally Merge changes from the original repo (again) Do an R CMD check using devtools::check() and aim for 0 errors and warnings. Commit and push your changes. Submit a pull request. If you are reviewing the pull request, wait until the travis-ci unit tests have finished Please make sure that the unit tests PASS before merging in!! 5.2 Code style Function names start with capital letters Variable names start with small letters Environments should be in ALL CAPS Reference Hadley’s style code &lt;- is preferred over = for assignment Indentation is with two spaces, not two or a tab. There should be no tabs in code files. if () {} else {} constructions should always use full curly braces even when usage seems unnecessary from a clarity perspective. TODO statements should be opened as GitHub issues with links to specific code files and code lines, rather than written inline. Follow Hadley’s suggestion for aligning long functions with many arguments: long_function_name &lt;- function(a = &quot;a long argument&quot;, b = &quot;another argument&quot;, c = &quot;another long argument&quot;) { # As usual code is indented by two spaces. } Never use print() to send text to the console. Instead use message(), warning(), and error() as appropriate. Use environment variables, not options(), to store global arguments that are used by many or all functions. "],
["manual-actions.html", "Chapter 6 Manual Actions 6.1 Sykdomspulsen", " Chapter 6 Manual Actions 6.1 Sykdomspulsen 6.1.1 Sykdomspulsen Weekly update The weekly update needs to be done every Tuesday morning. New data has arrived from Helsedirektoratet to FHI during Monday evening and night, and the further statistical analysis and updating of the interactive webpage for Sykdomspulsen is done on Tuesday. For more information about Sykdomspulsen setup: https://folkehelseinstituttet.github.io/dashboards/ https://folkehelseinstituttet.github.io/dashboards_sykdomspuls/ Log in to «Sikker sone» Click on «Sikkersone statistikk» Open R or R studio by clicking on the four squares in the bottom left corner, then on the arrow pointing downwards approximately in the same area and search for R in the upper right corner When R is open, click on “file” in the upper left corner, and then “open script” Open G:/Helseregistre/MSIS/Sykdomspulsen/Gry/FormattingWithinSikkersone/ SykdomspulsenWeeklyReport Slide the R-code so that it is beside the R console (so that you can see the whole R console) Put the marker within the R-code and click Ctrl+A, then click Ctrl+R After a few minutes, you will see a progress bar on the R-console, which shows how much of the code is finished. When the bar shows 100%, the whole code has run, and the results are finished (this takes about 1 hour, you can do other things while waiting for this) When the progress bar shows 100% you should look at the data that is shown in the console and see if the dates are from this week. If not you should contact the IT department by Cathrine Slorbak (Cathrine.Slorbak@fhi.no) and Gry Grøneng (GryMarysol.Groneng@fhi.no). There is probably something wrong with receiving the data from the Health directorate, hence the IT department needs to solve it. Do not continue until the problem is solved. If the dates look ok, you can close R (by clicking on x in the upper right corner). Go to “Windows explorer” by clicking on the four squares in the lower left corner (still in “sikker sone”), and go to: G:/Helseregistre/MSIS/Sykdomspulsen/Gry/ FormattingWithinSikkersone, and find a text file which is called “partially_formatted_ todays date.txt” (todays date is displayed 2017_06_13). You should look if the file is larger than last weeks file, it should be larger since we take out all the data every week, and more days have been added since last week. If the file is smaller than last week, contact the IT department by Cathrine Slorbak (Cathrine.Slorbak@fhi.no) and Gry Grøneng (GryMarysol.Groneng@fhi.no). Do not continue until the problem is solved. Copy and paste the file into the folder “Filer til ordinær sone (J:)” Log out of “sikker sone” and open the windows explorer in the ordinary zone and go to “Filer overført fra sikker sone (K:)” and find the file. Copy and paste the file into: F:/Prosjekter/sMSIS/WeeklyUpdates_Sykdomspulsen AND F:/Prosjekter/Dashboards/data_raw/sykdomspuls You have now done the weekly update of Sykdomspulsen! "]
=======
["index.html", "Dashboards project Preface", " Dashboards project Richard White 2018-11-12 Preface The dashboards project is a project at FHI concerned with running automated analyses on data. An automated analysis is any analysis that: Will be repeated multiple times in the future Always has an input dataset with consistent file structure Always has the same expected output (e.g. tables, graphs, reports) If you are just joining this project, please see the quickstart section. "],
["introduction.html", "1 Introduction 1.1 Executive summary 1.2 What is an automated analysis? 1.3 Why not have one project for each automated analysis? 1.4 Important repositories", " 1 Introduction 1.1 Executive summary The dashboards project is a project at FHI concerned with running automated analyses on data. In principle, the dashboards project is split up into two parts: The umbrella infrastructure (i.e. Docker containers, continuous integration, chron jobs, etc.) The R package for each automated analysis 1.2 What is an automated analysis? An automated analysis is any analysis that: Will be repeated multiple times in the future Always has an input dataset with consistent file structure Always has the same expected output (e.g. tables, graphs, reports) 1.3 Why not have one project for each automated analysis? Automated analyses have a lot of code and infrastructure in common. Automated analyses: Need their code to be tested via unit testing to ensure the results are correct Need their code to be tested via integration testing to ensure everything runs Need to be run at certain times Need to be able to send emails notifying people that the analyses have finished running Need to make their results accessible to the relevant people By combining them all in one umbrella project we can force everyone to use the same infrastructure and coding principles, so we: Only need to solve a problem once Only need to maintain one system Can easily work on multiple projects, as we all speak the same language 1.4 Important repositories 1.4.1 Infrastructure https://github.com/raubreywhite/dashboards_control/ (private) This contains the Dockerfiles, cronfiles, all bash scripts, etc. http://github.com/raubreywhite/docker/ This contains the base analysis Dockerfile https://rocker-project.org https://folkehelseinstituttet.github.io/fhi/ This is an R package that contains helper functions. 1.4.2 Automated analyses R packages https://folkehelseinstituttet.github.io/dashboards_sykdomspuls/ https://folkehelseinstituttet.github.io/dashboards_normomo/ https://folkehelseinstituttet.github.io/dashboards_sykdomspuls_pdf/ https://folkehelseinstituttet.github.io/dashboards_noispiah/ https://folkehelseinstituttet.github.io/dashboards_sykdomspuls_log/ "],
["umbrella.html", "2 Umbrella Infrastructure 2.1 Physical Hardware and Subscriptions 2.2 Configuration, Scripts, etc. 2.3 Analysis Docker Image 2.4 Reverse Proxy Docker Image 2.5 Docker Compose 2.6 Production Computer - smhb 2.7 Integration Testing Computer - linux 2.8 Unit Testing - travis-ci", " 2 Umbrella Infrastructure 2.1 Physical Hardware and Subscriptions One Github organization (http://github.com/folkehelseinstituttet/) One Github team (https://github.com/orgs/folkehelseinstituttet/teams/dashboards) One drat repository (https://folkehelseinstituttet.github.io/drat/) One travis-ci.org account (http://travis-ci.org/folkehelseinstituttet) One travis-ci.com account (http://travis-ci.com/folkehelseinstituttet) One Docker hub account (http://hub.docker.com/u/raw996/) At least three computers: Production linux computer smhb Integration testing linux computer linux Development linux computers (1 per person) 2.1.1 Requirements - smhb Git Docker Engine - Community (https://www.docker.com/products/docker-engine) 2.1.2 Requirements - linux Git Docker Engine - Community (https://www.docker.com/products/docker-engine) Jenkins installed via a Docker container (http://jenkins.io) 2.1.3 Requirements - dev Git Docker Engine - Community (https://www.docker.com/products/docker-engine) 2.2 Configuration, Scripts, etc. Most of the bash scripts, Docker files, passwords, etc. are all hosted at the private Github repository raubreywhite/dashboards_control. - $DASHBOARDS_FOLDER/dashboards_control/ |-- bin/ |-- dev_down.sh |-- dev_up.sh |-- docker_build.sh |-- docker_login.sh |-- docker_push_test_to_prod.sh |-- prod_down.sh |-- prod_up.sh |-- prod_update.sh |-- public.sh |-- test_noispiah.sh |-- test_normomo.sh |-- test_sykdomspuls_log.sh |-- test_sykdomspuls_pdf.sh |-- test_sykdomspuls.sh |-- infrastructure/ |-- dashboards_nginx/ |-- dashboards_r/ |-- add_autofs.sh |-- add_cron.sh |-- auto.mounts |-- crontab |-- Dockerfile |-- emails_sykdomspuls_alert_test.xlsx |-- emails_sykdomspuls_alert.xlsx |-- emails.xlsx |-- httr-oauth_2017_09_17 |-- mail.json |-- repo-key |-- secret.sh |-- dashboards_shiny/ |-- docker-compose-api.yml |-- docker-compose-dev.yml |-- docker-compose-prod.yml |-- docker-compose-test.yml 2.2.1 $DASHBOARDS_FOLDER/dashboards_control/bin/dev_down.sh Dev script to shut down docker-compose 2.2.2 $DASHBOARDS_FOLDER/dashboards_control/bin/dev_up.sh Dev script to start docker-compose 2.2.3 $DASHBOARDS_FOLDER/dashboards_control/bin/docker_build.sh Builds all relevant Docker containers 2.2.4 $DASHBOARDS_FOLDER/dashboards_control/bin/docker_login.sh Logs in to docker-hub 2.2.5 $DASHBOARDS_FOLDER/dashboards_control/bin/docker_push_test_to_prod.sh Retags ‘test’ Docker containers to ‘production’ and pushs them to docker-hub 2.2.6 $DASHBOARDS_FOLDER/dashboards_control/bin/prod_down.sh Only to be used on the production computer smhb. This bash script stops the docker-compose. Note: This script is not used. 2.2.7 $DASHBOARDS_FOLDER/dashboards_control/bin/prod_up.sh Only to be used on the production computer smhb. This bash script starts up the docker-compose. Note: This script is not used. 2.2.8 $DASHBOARDS_FOLDER/dashboards_control/bin/prod_update.sh Only to be used on the production computer smhb. This bash script: Removes unused Docker container/images (important so we don’t run out of space) Runs some scripts required for network access Pulls the latest version of raubreywhite/dashboards_control Stops the docker-compose-prod.yml Pulls the latest production images for: raw996/dashboards_r:production raw996/dashboards_nginx:production raw996/dashboards_shiny:production Starts the docker-compose-prod.yml 2.2.9 $DASHBOARDS_FOLDER/dashboards_control/bin/public.sh Lists a bunch of environmental variables 2.2.10 $DASHBOARDS_FOLDER/dashboards_control/bin/test_noispiah.sh Runs /r/noispiah/src/RunTest.R inside raw996/dashboards_r:test Note: This script is generally only run by Jenkins on linux as the integration testing for noispiah. 2.2.11 $DASHBOARDS_FOLDER/dashboards_control/bin/test_normomo.sh Runs /r/normomo/src/RunTest.R inside raw996/dashboards_r:test Note: This script is generally only run by Jenkins on linux as the integration testing for normomo. 2.2.12 $DASHBOARDS_FOLDER/dashboards_control/bin/test_sykdomspuls_log.sh Runs /r/sykdomspulslog/src/RunTest.R inside raw996/dashboards_r:test Note: This script is generally only run by Jenkins on linux as the integration testing for sykdomspuls_log. 2.2.13 $DASHBOARDS_FOLDER/dashboards_control/bin/test_sykdomspuls_pdf.sh Runs /r/sykdomspulspdf/src/RunTest.R inside raw996/dashboards_r:test Note: This script is generally only run by Jenkins on linux as the integration testing for sykdomspuls_pdf. 2.2.14 $DASHBOARDS_FOLDER/dashboards_control/bin/test_sykdomspuls.sh Runs /r/sykdomspuls/src/RunTest.R inside raw996/dashboards_r:test Note: This script is generally only run by Jenkins on linux as the integration testing for sykdomspuls. 2.2.15 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/add_autofs.sh See autofs. 2.2.16 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/add_cron.sh See cron. 2.2.17 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/auto.mounts See autofs. 2.2.18 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/crontab See cron. 2.2.19 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/Dockerfile See here. 2.2.20 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/emails_sykdomspuls_alert_test.xlsx A list of email addresses used in sykdomspuls. 2.2.21 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/emails_sykdomspuls_alert.xlsx A list of email addresses used in sykdomspuls. 2.2.22 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/emails.xlsx A list of email addresses used in many projects. 2.2.23 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/httr-oauth_2017_09_17 The authorization file for the dashboardsfhi@gmail.com. This probably needs to be refreshed every year?? 2.2.24 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/mail.json Related to httr-oauth. 2.2.25 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/repo-key The repo-key for downloading the private raubreywhite/dashboards_control repository. 2.2.26 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/dashboards_r/secret.sh Passwords. 2.2.27 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/docker-compose-api.yml Docker-compose file used for testing the API. 2.2.28 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/docker-compose-dev.yml Docker-compose file used for development. See here. 2.2.29 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/docker-compose-prod.yml Docker-compose file used for the production computer. See here. 2.2.30 $DASHBOARDS_FOLDER/dashboards_control/infrastructure/docker-compose-test.yml Docker-compose file used for integration testing of Jenkins on linux. See here. 2.3 Analysis Docker Image 2.3.1 Images Our analysis Docker images are based off the rocker images. More specifically, the rocker/verse:3.5.0 image. This Docker image is then expanded upon by a separate Dockerfile raw996/dhadley. This Docker image is automatically rebuilt by Jenkins on linux whenever the repository is updated. The resultant Docker image is pushed to raw996/dhadley:3.5.0. This image is a general-purpose analysis image, with no sensitive information in it. This Docker image is then expanded upon by a separate Dockerfile raw996/dashboards_r. This Docker image is automatically rebuilt by Jenkins on linux whenever the repository is updated. The resultant Docker image is locally tagged as raw996/dashboards_r:test and then a number of integration tests are performed on it. If the integration tests are passed, then the Docker image is retagged and pushed to raw996/dashboards_r:production. This image is private as it contains passwords and email addresses. 2.3.2 File Structure Inside raw996/dashboards_r we have the following file structure: /data_raw/ |-- normomo/ |-- noispiah/ |-- sykdomspuls/ |-- sykdomspuls_pdf/ |-- sykdomspuls_log/ /data_clean/ |-- normomo/ |-- noispiah/ |-- sykdomspuls/ |-- sykdomspuls_pdf/ |-- sykdomspuls_log/ /data_app/ |-- normomo/ |-- noispiah/ |-- sykdomspuls/ |-- sykdomspuls_pdf/ |-- sykdomspuls_log/ /results/ |-- normomo/ |-- noispiah/ |-- sykdomspuls/ |-- sykdomspuls_pdf/ |-- sykdomspuls_log/ /usr/local/lib/R/site-library/ &lt;soft linked to /r&gt; |-- &lt;OTHER R PACKAGES INSTALLED HERE&gt;/ |-- fhi/ |-- normomo/ |-- noispiah/ |-- sykdomspuls/ |-- sykdomspuls_pdf/ |-- sykdomspuls_log/ |-- &lt;OTHER R PACKAGES INSTALLED HERE&gt;/ Note that we have a soft link between /r and /usr/local/lib/R/site-library/. 2.3.3 cron We use cron to schedule the analyses. The schedule is specified in crontab. The cronjobs are only activated when the environmental variable ADD=cron is defined. Cronjobs are then activated through add_cron.sh. In principle, cronjobs should only be activated on smhb. 2.3.4 autofs We use autofs to connect to the F network. The network locations, username, and password are specified in auto.mounts. Autofs is only activated when the environmental variable ADD_AUTOFS=yes is defined. Autofs is then activated through add_autofs.sh. In principle, autofs should only be activated on smhb. 2.4 Reverse Proxy Docker Image We use nginx as a reverse proxy to make rstudio server available to the developers. The relevant Dockerfile is here and is pushed to raw996/dashboards_nginx:production after integration testing is passed. 2.5 Docker Compose Docker compose is used to integrate these Docker images into the local filesystem. We have multiple docker-compose files for different reasons: For production on smhb For testing on linux For development on a dev computer 2.6 Production Computer - smhb 2.6.1 crontab # m h dom mon dow command 5 1 * * * /home/raw996/git/dashboards_control/bin/prod_update.sh @reboot /home/raw996/git/dashboards_control/bin/prod_update.sh 2.6.2 File Structure /home/raw996/git/dashboards_control/ 2.6.3 Explanation smhb is designed to be extremely simple. It has two jobs: Updating raw996/dashboards_r:production, raw996/dashboards_shiny:production, and raw996/dashboards_nginx:production Making sure that docker-compose-prod.yml is running We purposefully minimize all integration with the base machine, because this enables us to be deploy-environment independent and to move our deployment anywhere with minimal hassle. 2.7 Integration Testing Computer - linux 2.7.1 File Structure /home/raw996/ |-- docker-compose-jenkins/ |-- docker-compose.yml |-- data/ |-- data_app/ |-- normomo/ |-- sykdomspuls/ |-- data_clean/ |-- normomo/ |-- sykdomspuls/ |-- data_raw/ |-- normomo/ |-- FHIDOD2_20170425.txt |-- sykdomspuls/ |-- partially_formatted_2017_08_01.txt |-- data_results/ |-- normomo/ |-- sykdomspuls/ |-- jenkins/ 2.7.2 Explanation linux has three jobs: Building [raw996/dhadley](https://github.com/raubreywhite/docker/blob/master/dhadley/Dockerfile Integration testing for the automated analyses Pushing raw996/dashboards_r:production, raw996/dashboards_shiny:production, and raw996/dashboards_nginx:production to Docker hub after successful integration testing Integration testing happens by Jenkins running: test_noispiah.sh test_normomo.sh test_sykdomspuls.sh test_sykdomspulslog.sh test_sykdomspulspdf.sh 2.8 Unit Testing - travis-ci Travis-ci is used for unit testing of packages. If the R package passes all tests, then we use drat to deploy a built version of the package to Folkehelseinstituttet’s R repository: https://folkehelseinstituttet.github.io/drat/. "],
["rpackages.html", "3 R packages 3.1 Overview 3.2 Requirements 3.3 Deployment via travis-ci and drat 3.4 Integration with the local file system 3.5 inst/src/RunProcess.R 3.6 inst/src/RunTest.R 3.7 inst/bin/0_run.sh", " 3 R packages 3.1 Overview Each automated analysis has its own R package: sykdomspuls normomo noispiah sykdomspulspdf sykdomspulslog Each R package contains all of the code necessary for that automated analysis. Typical examples are: Data cleaning Signal analysis Graph generation Report generation 3.2 Requirements The R packages should be developed using unit testing as implemented in the testthat package. Furthermore, the R package should operate (and be able to be tested) independently from the real datasets on the system. This is because the real datasets cannot be shared publically or uploaded to github. To circumvent this issue, each package will need to develop functions that can generate fake data. GenFakeDataRaw is one example from sykdomspuls. We also require that unit tests are created to test the formatting/structure of results. ValidateAnalysisResults is one example from sykdomspuls, where the names of the data.table are checked against reference values to ensure that the structure of the results are not accidentally changed. 3.3 Deployment via travis-ci and drat Unit testing is then automatically run using travis-ci. If the R package passes all tests, then we use drat to deploy a built version of the package to Folkehelseinstituttet’s R repository: https://folkehelseinstituttet.github.io/drat/. 3.4 Integration with the local file system We assume that the local file system follows this file structure, and this is provided via Docker-compose from the umbrella infrastructure. Referencing the data_raw, data_clean, data_app, and results folders are done through the the fhi package. 3.5 inst/src/RunProcess.R An automated analysis needs to: Know the location of the data/results folders. Check for new data in these folders. If no new data - then quit. Load in the data. Load in the analysis functions. Run the analyses. Save the results. RunProcess.R is responsible for these tasks. We can think of it as an extremely short and extremely high-level script that implements the analysis scripts. Depending on the automated analysis RunProcess.R can be run every two minutes (constantly checking for new data), or once a week (when we know that data will only be available on a certain day/time). 3.6 inst/src/RunTest.R This file is the brains of the integrated testing. This file will be run by the $DASHBOARDS_FOLDER/dashboards_control/bin/test_*.sh files. 3.7 inst/bin/0_run.sh This file is used to: Do any pre-analysis steps (e.g. download new data from an SFTP server) Run inst/src/RunProcess.R /usr/local/bin/Rscript /r/ANALYSIS/src/RunProcess.R Do any post-analysis steps (e.g. upload results to an SFTP server) This file will be run by cron. "],
["contributingquickstart.html", "4 Contributing/Quickstart 4.1 Quickstart 4.2 New Automated Analysis 4.3 Development guidelines 4.4 Code style", " 4 Contributing/Quickstart 4.1 Quickstart Create a project folder for your code (let us say ~/git/dashboards). This folder will be accessible from inside your Docker container as /dashboards/ Create a project folder for your data (let us say ~/data/). Clone the following repos inside ~/git/dashboards: https://github.com/raubreywhite/dashboards_control/ (private) Fork the following repos, and then clone the forks to your computer inside ~/git/dashboards: https://github.com/folkehelseinstituttet/dashboards/ https://github.com/folkehelseinstituttet/dashboards_sykdomspuls/ https://github.com/folkehelseinstituttet/dashboards_normomo/ https://github.com/folkehelseinstituttet/dashboards_sykdomspulspdf/ https://github.com/folkehelseinstituttet/dashboards_noispiah/ https://github.com/folkehelseinstituttet/dashboards_sykdomspulslog/ For each repo, add the folkehelseinstitutet repository as your upstream: git remote add upstream https://github.com/folkehelseinstituttet/ORIGINAL_REPOSITORY.git In your ~/.profile add the following three lines: export DASHBOARDS_DATA=~/data/ export DASHBOARDS_FOLDER=~/git/dashboards/ export PATH=$PATH:$DASHBOARDS_FOLDER/dashboards_control/bin/ Build your Dockerfiles: docker_build.sh A number of folders will have been automatically created (see below). Please put in your development datafiles into the appropriate data_raw/ folder: - $DASHBOARDS_DATA/ |-- data_app/ |-- sykdomspuls/ |-- normomo/ |-- sykdomspuls_log/ |-- sykdomspuls_pdf/ |-- data_clean/ |-- sykdomspuls/ |-- normomo/ |-- sykdomspuls_log/ |-- sykdomspuls_pdf/ |-- data_raw/ |-- sykdomspuls/ |-- normomo/ |-- sykdomspuls_log/ |-- sykdomspuls_pdf/ |-- results/ |-- sykdomspuls/ |-- normomo/ |-- sykdomspuls_log/ |-- sykdomspuls_pdf/ 9 Run your docker-compose: dev_up.sh Open a browser and go to http://localhost:8788/ Login using username=rstudio and password=rstudio1 Using the project menu, open the project corresponding to the automated analysis you are interested in. This should be located at /dashboards/. 4.2 New Automated Analysis This will walk you through the creation of a new automated analysis called “yyyy”. Create a new repository on folkehelseinstituttet with the name dashboards_yyyy. Fork this repository to your Github account Clone the forked repository to ~/git/dashboards/dashboards_xxxx Download dashboards_template and copy all of its contents into ~/git/dashboards/dashboards_yyyy Edit the following files: ~/git/dashboards/dashboards_yyyy/DESCRIPTION (Package: xxxx -&gt; Package: yyyy) ~/git/dashboards/dashboards_yyyy/tests/testthat.R (library(xxxx)-&gt;library(yyyy)) ~/git/dashboards/dashboards_yyyy/.travis.yml (xxxx-&gt;yyyy) ~/git/dashboards/dashboards_yyyy/inst/bin/0_run.sh (xxxx-&gt;yyyy) ~/git/dashboards/dashboards_yyyy/inst/src/RunProcess.sh (xxxx-&gt;yyyy) ~/git/dashboards/dashboards_yyyy/inst/src/RunTest.sh (xxxx-&gt;yyyy) Ask Richard to log into travis-ci.com and add the GITHUB_PAT environmental variable to activate continuous integration for yyyy Submit pull requests and ensure that: Everything works The package is successfully build and included in https://github.com/folkehelseinstituttet/drat/tree/gh-pages/src/contrib Add your package under the secton “## DRAT PACKAGES FROM FHI” at https://github.com/raubreywhite/dashboards_control/blob/master/infrastructure/dashboards_r/Dockerfile Create the 4 folders data_raw, data_clean, results, data_app at https://github.com/raubreywhite/dashboards_control/blob/master/infrastructure/dashboards_r/Dockerfile Add your package’s 0_run.sh to https://github.com/raubreywhite/dashboards_control/blob/master/infrastructure/dashboards_r/crontab Add your package’s test_yyyy.sh to Jenkins on Linux Hope it works! 4.3 Development guidelines We try to follow the GitHub flow for development. If you have forked and cloned the project before and it has been a while since you worked on it, merge changes from the original repo to your clone by using: git fetch upstream git merge upstream/master Open the RStudio project file (.Rproj). Make your changes: Write your code. Test your code (bonus points for adding unit tests). Document your code (see function documentation above). Do an R CMD check using devtools::check() and aim for 0 errors and warnings. Commit your changes locally Merge changes from the original repo (again) Do an R CMD check using devtools::check() and aim for 0 errors and warnings. Commit and push your changes. Submit a pull request. If you are reviewing the pull request, wait until the travis-ci unit tests have finished Please make sure that the unit tests PASS before merging in!! 4.4 Code style Function names start with capital letters Variable names start with small letters Environments should be in ALL CAPS Reference Hadley’s style code &lt;- is preferred over = for assignment Indentation is with two spaces, not two or a tab. There should be no tabs in code files. if () {} else {} constructions should always use full curly braces even when usage seems unnecessary from a clarity perspective. TODO statements should be opened as GitHub issues with links to specific code files and code lines, rather than written inline. Follow Hadley’s suggestion for aligning long functions with many arguments: long_function_name &lt;- function(a = &quot;a long argument&quot;, b = &quot;another argument&quot;, c = &quot;another long argument&quot;) { # As usual code is indented by two spaces. } Never use print() to send text to the console. Instead use message(), warning(), and error() as appropriate. Use environment variables, not options(), to store global arguments that are used by many or all functions. "]
>>>>>>> upstream/master
]
